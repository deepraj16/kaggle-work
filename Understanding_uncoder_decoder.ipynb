{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOAPkGmXnKFeHujrxxZYzgS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepraj16/kaggle-work/blob/main/Understanding_uncoder_decoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjJ5G6isMdHa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X2u0g75gOQLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle\n"
      ],
      "metadata": {
        "id": "ghChi8_UNnGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"umasrikakollu72/hindi-english-truncated-corpus\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "EyKunF0tNvpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/root/.cache/kagglehub/datasets/umasrikakollu72/hindi-english-truncated-corpus/versions/1\")"
      ],
      "metadata": {
        "id": "PuSZNNLTODJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "path = \"/root/.cache/kagglehub/datasets/umasrikakollu72/hindi-english-truncated-corpus/versions/1\"\n",
        "print(os.listdir(path))"
      ],
      "metadata": {
        "id": "71y7xxZtOGAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(os.path.join(path, \"Hindi_English_Truncated_Corpus.csv\"))"
      ],
      "metadata": {
        "id": "O6u-Kc43PFGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "id": "nE0iSOeoPL1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines = df\n",
        "lines = lines[lines['source'] == 'ted'][['english_sentence', 'hindi_sentence']].dropna().drop_duplicates()\n",
        "lines = lines.sample(n=25000, random_state=42)\n"
      ],
      "metadata": {
        "id": "1xWqxxn0POAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "def clean_text(text):\n",
        "    exclude = set(string.punctuation)\n",
        "    text = ''.join(ch for ch in text if ch not in exclude)\n",
        "    text = text.translate(str.maketrans('', '', string.digits))\n",
        "    return text.strip().lower()"
      ],
      "metadata": {
        "id": "Rh8xexryPVam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines['english_sentence'] = lines['english_sentence'].apply(clean_text)\n",
        "lines['hindi_sentence'] = lines['hindi_sentence'].apply(clean_text)\n",
        "lines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x: 'start_ ' + x + ' _end')"
      ],
      "metadata": {
        "id": "H6vgCGotPX6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng_tokenizer = Tokenizer()\n",
        "eng_tokenizer.fit_on_texts(lines['english_sentence'])\n",
        "eng_seq = eng_tokenizer.texts_to_sequences(lines['english_sentence'])\n",
        "\n",
        "hin_tokenizer = Tokenizer(filters='')\n",
        "hin_tokenizer.fit_on_texts(lines['hindi_sentence'])\n",
        "hin_seq = hin_tokenizer.texts_to_sequences(lines['hindi_sentence'])"
      ],
      "metadata": {
        "id": "U61kh5IWPkD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_eng_len = max(len(seq) for seq in eng_seq)\n",
        "max_hin_len = max(len(seq) for seq in hin_seq)\n",
        "\n",
        "encoder_input = pad_sequences(eng_seq, maxlen=max_eng_len, padding='post')\n",
        "decoder_input = pad_sequences(hin_seq, maxlen=max_hin_len, padding='post')"
      ],
      "metadata": {
        "id": "AZd5-9RbPzAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_target = np.zeros((decoder_input.shape[0], decoder_input.shape[1], 1))\n",
        "decoder_target[:, 0:-1, 0] = decoder_input[:, 1:]"
      ],
      "metadata": {
        "id": "ONrdUL8UP1XT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BbIEij91QAkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, LSTM\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "eng_vocab_size = 25000\n",
        "latent_dim = 20\n"
      ],
      "metadata": {
        "id": "L98u1RA3QDSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, LSTM\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Define input layer\n",
        "encoder_inputs = Input(shape=(None,), name=\"encoder_input\")\n",
        "\n",
        "# Embedding layer\n",
        "enc_emb = Embedding(input_dim=eng_vocab_size, output_dim=latent_dim, name=\"encoder_embedding\")(encoder_inputs)\n",
        "\n",
        "# LSTM layer\n",
        "enc_outputs, state_h, state_c = LSTM(latent_dim, return_state=True, name=\"encoder_lstm\")(enc_emb)\n",
        "\n",
        "# Encoder states to be passed to the decoder\n",
        "encoder_states = [state_h, state_c]\n"
      ],
      "metadata": {
        "id": "9csFSKhsQEK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense\n",
        "\n",
        "# Decoder input\n",
        "decoder_inputs = Input(shape=(None,), name=\"decoder_input\")\n",
        "hin_vocab_size =25000   # üîÅ Set this to your actual Hindi vocabulary size\n",
        "latent_dim = 30        # üîÅ Match with encoder's latent_dim\n",
        "encoder_states = [state_h, state_c]  # from encoder LSTM\n",
        "\n",
        "dec_emb_layer = Embedding(input_dim=hin_vocab_size, output_dim=latent_dim, name=\"decoder_embedding\")\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# LSTM with encoder states as initial state\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name=\"decoder_lstm\")\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
        "\n",
        "# Dense softmax layer to predict output tokens\n",
        "decoder_dense = Dense(hin_vocab_size, activation='softmax', name=\"decoder_output\")\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n"
      ],
      "metadata": {
        "id": "YYAaoWcsQUTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.fit(\n",
        "    [encoder_input, decoder_input],\n",
        "    decoder_target,\n",
        "    batch_size=64,\n",
        "    epochs=15,\n",
        "    validation_split=0.2\n",
        ")\n"
      ],
      "metadata": {
        "id": "0_rwrCHiQdp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kAemEg__Q4oQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "latent_dim = 256\n",
        "eng_vocab_size = 10000\n",
        "hin_vocab_size = 10000\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(None,), name='encoder_input')\n",
        "enc_emb = Embedding(input_dim=eng_vocab_size, output_dim=latent_dim)(encoder_inputs)\n",
        "_, state_h, state_c = LSTM(latent_dim, return_state=True)(enc_emb)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = Input(shape=(None,), name='decoder_input')\n",
        "dec_emb = Embedding(input_dim=hin_vocab_size, output_dim=latent_dim)(decoder_inputs)\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
        "print(\"Before Dense:\", decoder_outputs.shape)  # (batch_size, seq_len, latent_dim)\n",
        "\n",
        "decoder_dense = Dense(hin_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "print(\"After Dense:\", decoder_outputs.shape)  # (batch_size, seq_len, hin_vocab_size)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n"
      ],
      "metadata": {
        "id": "3n7OmK7fRFEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6l62_n3sRJaJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}